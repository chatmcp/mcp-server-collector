# Generated by https://smithery.ai. See: https://smithery.ai/docs/config#dockerfile
# Use a Python image with uv pre-installed
FROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv

# Set up working directory
WORKDIR /app

# Copy pyproject.toml and lock file to set up dependencies first
COPY pyproject.toml uv.lock /app/

# Enable bytecode compilation
ENV UV_COMPILE_BYTECODE=1

# Copy from the cache instead of linking since it's a mounted volume
ENV UV_LINK_MODE=copy

# Install the project's dependencies using the lockfile
RUN --mount=type=cache,target=/root/.cache/uv uv sync --frozen --no-install-project --no-dev --no-editable

# Then, add the rest of the project source code and install it
# Installing separately from its dependencies allows optimal layer caching
COPY src /app/src

RUN --mount=type=cache,target=/root/.cache/uv uv sync --frozen --no-dev --no-editable

# Add the .env file (make sure to fill in the actual values before building)
COPY .env /app/.env

FROM python:3.12-slim-bookworm

WORKDIR /app

COPY --from=uv /root/.local /root/.local
COPY --from=uv --chown=app:app /app/.venv /app/.venv
COPY --from=uv /app/src /app/src

# Place executables in the environment at the front of the path
ENV PATH="/app/.venv/bin:$PATH"

# Define environment variables for the service
ENV OPENAI_API_KEY="your_openai_api_key_here"
ENV OPENAI_BASE_URL="https://api.openai.com/v1"
ENV OPENAI_MODEL="gpt-4o-mini"
ENV MCP_SERVER_SUBMIT_URL="https://mcp.so/api/submit-project"

# Set the entrypoint to run the server
ENTRYPOINT ["uv", "run", "mcp-server-collector"]